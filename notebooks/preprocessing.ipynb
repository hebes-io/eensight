{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30997a83",
   "metadata": {},
   "source": [
    "# The preprocessing pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4461ba74",
   "metadata": {},
   "source": [
    "### The goal of the preprocessing pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600d4b53",
   "metadata": {},
   "source": [
    "The data preprocessing pipeline that is presented in this chapter assumes that energy consumption and outdoor air temperature is the only data that is available for M&V. We consider an energy consumption and outdoor air temperature dataset validated if:\n",
    "    \n",
    "    \n",
    "1. **There are no duplicate values in the dataset’s timestamps**. Duplicate timestamps are treated separately for energy consumption and for temperature data. In both cases, if the range of the energy consumption or temperature values that share a timestamp is short – according to a user-defined threshold– they are replaced by their average. Otherwise, they are treated as missing values.\n",
    "\n",
    "\n",
    "2. **There are no missing values in the dataset’s timestamps**. If there are missing timestamps, they are added and the respective data is treated as missing values.\n",
    "\n",
    "\n",
    "3. **Potential outliers are identified and marked**. Outlier detection is carried out separately for energy consumption and for temperature data. \n",
    "\n",
    "\n",
    "4. **There is enough data available for the energy consumption of the building under study**. Baseline energy consumption data must cover at least one full year before any energy efficiency intervention. In addition, and adopting the data requirements of the [CalTRACK](https://www.caltrack.org/) set of methods, data must be available for over 90% of hours in each calendar month – ***after excluding the potential outliers***.\n",
    "\n",
    "\n",
    "5. **There are no missing values in the outdoor air temperature data**. If temperature data is missing, the missing values are imputed. The outdoor air temperature changes smoothly from one hour to the next, so interpolating over a 6-hour window around a missing observation is a sensible approach for imputation. This is in line with CalTRACK's requirement that temperature data may not be missing for more than six (6) consecutive hours.\n",
    "\n",
    "\n",
    "6. **There are no missing values in the energy consumption data**. Missing values for energy consumption data do not pose a problem when training the predictive baseline model but they may lead to daily consumption profiles that are mistakenly regarded as unusual when we search for common and uncommon patterns in the data. Accordingly, the proposed workflow imputes the energy consumption data for the identification of patterns in the daily consumption, but ***does not include*** the imputed values in the dataset that is used for the predictive model’s training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768c2e3b",
   "metadata": {},
   "source": [
    "The steps of the preprocessing pipeline are summarized in the figure below:\n",
    "\n",
    "<img src=\"html/figures/01.png\" width=\"500\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ab8aa3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b94c9ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datetime import date, datetime, timedelta\n",
    "\n",
    "pd.plotting.register_matplotlib_converters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41535471",
   "metadata": {},
   "outputs": [],
   "source": [
    "from eensight.io import DataCatalog\n",
    "from eensight.utils import load_configuration, fit_pdf\n",
    "from eensight.prediction.linear_models import seasonal_predict\n",
    "\n",
    "from eensight.preprocessing import linear_impute, iterative_impute\n",
    "from eensight.preprocessing import validate_data, check_column_values_not_null \n",
    "from eensight.preprocessing import global_filter, global_outlier_detect, local_outlier_detect\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f55258",
   "metadata": {},
   "source": [
    "### Load the data catalog for Demo Building #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "253edd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = load_configuration(catalog='demo_site_01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56260b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = DataCatalog.from_config(catalog=cfg.catalog, \n",
    "                                  data_dir=cfg.data_dir, \n",
    "                                  ml_stages='train')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e3861c",
   "metadata": {},
   "source": [
    "### Select the consumption dataset from the demo catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9237ab0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "consumption = catalog.load('consumption_train')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff8699c",
   "metadata": {},
   "source": [
    "### Make sure that the data is in the appropriate format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dad7d37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "consumption = validate_data(consumption, col_name='consumption', date_col_name='timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcf37ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.style.context('seaborn-whitegrid'):    \n",
    "    fig = plt.figure(figsize=(12, 3.54), dpi=96)\n",
    "    layout = (1, 1)\n",
    "    ax = plt.subplot2grid(layout, (0, 0))\n",
    "\n",
    "    consumption['consumption'].plot(ax=ax, alpha=0.5)\n",
    "    ax.set_xlabel('Hours')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7192561",
   "metadata": {},
   "source": [
    "### Outlier identification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39a5f8c",
   "metadata": {},
   "source": [
    "The proposed approach for outlier identification is outlined next:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813d68f7",
   "metadata": {},
   "source": [
    "#### Step 1: Global filter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef112940",
   "metadata": {},
   "source": [
    "The first step screens for non-physically plausible values as well as unlikely values in the data. \n",
    "\n",
    "For power consumption data, negative and zero values are filtered out. \n",
    "\n",
    "For both consumption and temperature data, values that are at least 10 times larger than the median value are also removed. The threshold of ten times the median value aims at removing the most extreme outliers. \n",
    "\n",
    "Furthermore, long streaks of constant values are filtered out as well (here *long* is defined in hours by `no_change_window`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7444767",
   "metadata": {},
   "outputs": [],
   "source": [
    "consumption['consumption'] = global_filter(consumption['consumption'], \n",
    "                                           no_change_window=3,\n",
    "                                           allow_zero=False, \n",
    "                                           allow_negative=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e46a57",
   "metadata": {},
   "source": [
    "#### Step 2: Seasonal filter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c107308a",
   "metadata": {},
   "source": [
    "The second step captures the seasonal cycle of the data through a trend and seasonality decomposition approach that utilizes a Fourier series expansion of the form:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e36368",
   "metadata": {},
   "source": [
    "$$y(t)=\\alpha+bt+\\sum_{n=1}^{N} (\\alpha_n\\cos(\\frac{2πnt}{P}) + b_n\\sin(\\frac{2πnt}{P}))$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04e4652",
   "metadata": {},
   "source": [
    "where:\n",
    "\n",
    "$\\alpha$    is the offset of the linear trend\n",
    "\n",
    "$b$    is the slope of the linear trend\n",
    "\n",
    "$t$    is the day since a pre-specified epoch. For hourly data, $t$ will take decimal number values.\n",
    "\n",
    "$N$    is a parameter that controls the flexibility of the expansion. Suggested values are N=4 for daily seasonality, N=10 for yearly seasonality (see [Taylor S. J. and Letham B. (2018) \"Forecasting at scale,\" The American Statistician 72(1), pp. 37-45](https://peerj.com/preprints/3190/))\n",
    "\n",
    "$P$    is the length of the seasonality: P=1 for daily seasonality, P=365.25 for yearly seasonality. For energy consumption data, we fit a different daily seasonality component for each day of the week.  \n",
    "\n",
    "$\\alpha_n, b_n$\tRegression coefficients for the Fourier series expansion terms.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14842a46",
   "metadata": {},
   "source": [
    "The reason for applying seasonal decomposition before outlier identification can be seen in the figure below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21110024",
   "metadata": {},
   "outputs": [],
   "source": [
    "consumption_ = consumption['consumption'].dropna().values\n",
    "x_d = np.linspace(consumption_.min(), consumption_.max(), 2000)\n",
    "params, pdf = fit_pdf(x_d, consumption_)\n",
    "\n",
    "with plt.style.context('seaborn-whitegrid'):    \n",
    "    fig = plt.figure(figsize=(12, 3.54), dpi=96)\n",
    "    layout = (1, 1)\n",
    "    ax = plt.subplot2grid(layout, (0, 0))\n",
    "    \n",
    "    consumption['consumption'].plot(kind='hist', bins=100, density=True, alpha=0.3, ax=ax)\n",
    "    pd.Series(pdf, x_d).plot(ax=ax)\n",
    "    \n",
    "    ax.legend(['Fitted Normal distribution', 'Actual distribution of power consumption'], \n",
    "              frameon=True, shadow=True, fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edaf1419",
   "metadata": {},
   "source": [
    "Since seasonality leads to multimodal distributions, methods that rely on the assumption that the data follows a Normal distribution – such as simple three-sigma rules, the Grubbs test or the Extreme Studentized Deviate (ESD) test  – should generally be used only ***after*** a seasonal filter has been applied to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "495173eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = seasonal_predict(consumption, target_name='consumption')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4f6456",
   "metadata": {},
   "source": [
    "The next plot shows the actual and the predicted power consumption for the first and the last month of 2016:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cfdc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.style.context('seaborn-whitegrid'):    \n",
    "    fig = plt.figure(figsize=(12, 7), dpi=96)\n",
    "    layout = (2, 1)\n",
    "    ax1 = plt.subplot2grid(layout, (0, 0))\n",
    "    ax2 = plt.subplot2grid(layout, (1, 0))\n",
    "\n",
    "    start = datetime(2016, 1, 1, 0)\n",
    "    end = datetime(2016, 2, 1, 0)\n",
    "    consumption['consumption'].loc[start:end].plot(ax=ax1, alpha=0.6)\n",
    "    result.predicted.loc[start:end].plot(ax=ax1, alpha=0.4)\n",
    "    ax1.set_xlabel('Hours')\n",
    "    ax1.legend(['Power consumption', 'Seasonal prediction'], frameon=True, shadow=True)\n",
    "    \n",
    "    start = datetime(2016, 12, 1, 0)\n",
    "    end = datetime(2017, 1, 1, 0)\n",
    "    consumption['consumption'].loc[start:end].plot(ax=ax2, alpha=0.6)\n",
    "    result.predicted.loc[start:end].plot(ax=ax2, alpha=0.4)\n",
    "    ax2.set_xlabel('Hours')\n",
    "    ax2.legend(['Power consumption', 'Seasonal prediction'], frameon=True, shadow=True)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7128d9af",
   "metadata": {},
   "source": [
    "An overall sense for the quality of the fit can be gained by plotting a scatter plot of actual and predicted values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2330f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.style.context('seaborn-whitegrid'):    \n",
    "    fig = plt.figure(figsize=(12, 3.54), dpi=96)\n",
    "    layout = (1, 1)\n",
    "    ax = plt.subplot2grid(layout, (0, 0))\n",
    "    \n",
    "    sns.regplot(x=result.predicted, y=consumption['consumption'], ax=ax, \n",
    "                scatter_kws=dict(alpha=0.01))\n",
    "    \n",
    "    ax.set_xlabel('Predicted consumption')\n",
    "    ax.set_ylabel('Actual consumption')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ebe794",
   "metadata": {},
   "source": [
    "The next plot shows the distribution of the residuals when subtracting the actual from the predicted power consumption. The distribution of the residuals resembles a Student’s t distribution and, hence, it is easier to work with for detecting outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ca748c",
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals_ = result.resid.dropna()\n",
    "x_d = np.linspace(residuals_.min(), residuals_.max(), 2000)\n",
    "\n",
    "_, pdf_normal = fit_pdf(x_d, residuals_)\n",
    "_, pdf_t = fit_pdf(x_d, residuals_, distribution=stats.t)\n",
    "\n",
    "\n",
    "with plt.style.context('seaborn-whitegrid'):    \n",
    "    fig = plt.figure(figsize=(12, 3.54), dpi=96)\n",
    "    layout = (1, 1)\n",
    "    ax = plt.subplot2grid(layout, (0, 0))\n",
    "    \n",
    "    result.resid.plot(kind='hist', bins=100, density=True, alpha=0.3, ax=ax)\n",
    "    pd.Series(pdf_normal, x_d).plot(ax=ax)\n",
    "    pd.Series(pdf_t, x_d).plot(ax=ax)\n",
    "    \n",
    "    ax.legend(['Fitted Normal distribution', 'Fitted Student\\'s t distribution',\n",
    "               'Distribution of residuals'], \n",
    "              frameon=True, shadow=True, fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645a49dd",
   "metadata": {},
   "source": [
    "#### Step 3: Global outlier detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5376cb4",
   "metadata": {},
   "source": [
    "The third step of the outlier detection process identifies observations in the available dataset as potential outliers if the value of their corresponding residuals lies outside the range defined by:\n",
    "\n",
    "$$[mean^{all} - c\\times scale^{all}, mean^{all} + c\\times scale^{all}]$$\n",
    "\n",
    "where:\n",
    "\n",
    "$mean^{all}$ is the mean of a Student’s t distribution fitted on all the residual values\n",
    "\n",
    "$scale^{all}$ is the scale of a Student’s t distribution fitted on all the residual values\n",
    "\n",
    "$c$ is a user defined parameter (suggested value is 4).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d2a32a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers_global = global_outlier_detect(result.resid, c=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857d5680",
   "metadata": {},
   "source": [
    "The next plot shows the potential outliers in power consumption identified using the global outlier detection for January and December 2016:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fd01e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = consumption.loc[consumption.index.isin(outliers_global[outliers_global].index), \n",
    "                         'consumption']\n",
    "\n",
    "with plt.style.context('seaborn-whitegrid'):    \n",
    "    fig = plt.figure(figsize=(12, 6), dpi=96)\n",
    "    layout = (2, 1)\n",
    "    ax1 = plt.subplot2grid(layout, (0, 0))\n",
    "    ax2 = plt.subplot2grid(layout, (1, 0))\n",
    "    \n",
    "    start = datetime(2016, 1, 1, 0)\n",
    "    end = datetime(2016, 2, 1, 0)\n",
    "    consumption['consumption'].loc[start:end].plot(ax=ax1, alpha=0.6)\n",
    "    subset.loc[start:end].plot(ax=ax1, style='o', ms=4, c='red', alpha=0.4)\n",
    "    ax1.set_xlabel('Hours')\n",
    "    ax1.legend(['Power consumption', 'Potential global outliers'], frameon=True, shadow=True)\n",
    "    \n",
    "    start = datetime(2016, 12, 1, 0)\n",
    "    end = datetime(2017, 1, 1, 0)\n",
    "    consumption['consumption'].loc[start:end].plot(ax=ax2, alpha=0.6)\n",
    "    subset.loc[start:end].plot(ax=ax2, style='o', ms=4, c='red', alpha=0.4)\n",
    "    ax2.set_xlabel('Hours')\n",
    "    ax2.legend(['Power consumption', 'Potential global outliers'], frameon=True, shadow=True)\n",
    "    \n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4ca931",
   "metadata": {},
   "source": [
    "#### Step 4: Local outlier detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8110e7d2",
   "metadata": {},
   "source": [
    "The final step of the outlier detection process retains from the outliers identified in the previous step only those that can be characterised as outliers when we also compare their values with the observations in the same day of the year. \n",
    "\n",
    "The rationale for this approach can be explained by looking at the next plot, which shows the actual and the predicted power consumption during the first two (2) weeks of 2016 in the dataset. An important observation from the plot is that the distance from the seasonal model’s predictions is not by itself enough for detecting outliers when the whole day is misrepresented by the model (here a holiday is treated as a normal day)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8875868e",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime(2016, 1, 1, 0)\n",
    "end = datetime(2016, 1, 1, 0) + timedelta(days=14)\n",
    "\n",
    "with plt.style.context('seaborn-whitegrid'):    \n",
    "    fig = plt.figure(figsize=(12, 3.54), dpi=96)\n",
    "    layout = (1, 1)\n",
    "    ax = plt.subplot2grid(layout, (0, 0))\n",
    "\n",
    "    consumption['consumption'].loc[start:end].plot(ax=ax, alpha=0.8)\n",
    "    result.predicted.loc[start:end].plot(ax=ax, alpha=0.4)\n",
    "    \n",
    "    ax.set_ylim(top=7000)\n",
    "    ax.annotate(' First day of year ', xy=(datetime(2016, 1, 1, 12), 2200),  xycoords='data',\n",
    "             xytext=(40, 140), textcoords='offset points',\n",
    "             size=13, ha='center', va=\"center\",\n",
    "             bbox=dict(boxstyle=\"round\", alpha=0.3),\n",
    "             arrowprops=dict(arrowstyle=\"wedge,tail_width=0.5\", alpha=0.3))\n",
    "    \n",
    "    ax.set_xlabel('Hours')\n",
    "    ax.legend(['Power consumption', 'Seasonal prediction'], frameon=True, shadow=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c50ee24",
   "metadata": {},
   "source": [
    "Accordingly, the observations in the available dataset are marked as potential outliers if the value of their corresponding residuals lies outside the range defined by:\n",
    "\n",
    "$$[median^{day} - c\\times mad^{day}, median^{day} + c\\times mad^{day}]$$\n",
    "\n",
    "where:\n",
    "\n",
    "$median^{day}$ is the median of all the residual values in the corresponding day\n",
    "\n",
    "$mad^{day}$ is the median absolute deviation of all the residual values in the corresponding day\n",
    "\n",
    "$c$ is a user defined parameter (suggested value is 4).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6159c8ff",
   "metadata": {},
   "source": [
    "This step is parameterised by the minimum percentage of observations `min_samples` that must be available for any given day so that to take the daily statistics into account. If the number of the available observations is lower than this threshold, only the global outlier detection results are considered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "574940c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers_local = local_outlier_detect(result.resid, min_samples=0.6, c=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f197e92",
   "metadata": {},
   "source": [
    "The next plot shows the potential outliers in power consumption identified using the local outlier detection for January and December 2016:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251e8f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = consumption.loc[consumption.index.isin(outliers_local[outliers_local].index), \n",
    "                         'consumption']\n",
    "\n",
    "with plt.style.context('seaborn-whitegrid'):    \n",
    "    fig = plt.figure(figsize=(12, 6), dpi=96)\n",
    "    layout = (2, 1)\n",
    "    ax1 = plt.subplot2grid(layout, (0, 0))\n",
    "    ax2 = plt.subplot2grid(layout, (1, 0))\n",
    "    \n",
    "    start = datetime(2016, 1, 1, 0)\n",
    "    end = datetime(2016, 2, 1, 0)\n",
    "    consumption['consumption'].loc[start:end].plot(ax=ax1, alpha=0.6)\n",
    "    subset.loc[start:end].plot(ax=ax1, style='o', ms=4, c='red', alpha=0.4)\n",
    "    ax1.set_xlabel('Hours')\n",
    "    ax1.legend(['Power consumption', 'Potential local outliers'], frameon=True, shadow=True)\n",
    "    \n",
    "    start = datetime(2016, 12, 1, 0)\n",
    "    end = datetime(2017, 1, 1, 0)\n",
    "    consumption['consumption'].loc[start:end].plot(ax=ax2, alpha=0.6)\n",
    "    subset.loc[start:end].plot(ax=ax2, style='o', ms=4, c='red', alpha=0.4)\n",
    "    ax2.set_xlabel('Hours')\n",
    "    ax2.legend(['Power consumption', 'Potential local outliers'], frameon=True, shadow=True)\n",
    "    \n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8772dbb",
   "metadata": {},
   "source": [
    "For an observation to be marked as an outlier, both global and local results must agree. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "64e74521",
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers = np.logical_and(outliers_global, outliers_local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73dae7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.style.context('seaborn-whitegrid'):    \n",
    "    fig = plt.figure(figsize=(12, 3.54), dpi=96)\n",
    "    layout = (1, 1)\n",
    "    ax = plt.subplot2grid(layout, (0, 0))\n",
    "    \n",
    "    consumption['consumption'].plot(ax=ax, alpha=0.6)\n",
    "    \n",
    "    subset = consumption.loc[consumption.index.isin(outliers[outliers==True].index), \n",
    "                             'consumption']\n",
    "    subset.plot(ax=ax, style='o', ms=3, c='red')\n",
    "    \n",
    "    ax.set_xlabel('Hours')\n",
    "    ax.legend(['Power consumption', 'Potential outliers'], frameon=True, shadow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b060c8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "consumption['consumption'] = consumption['consumption'].mask(outliers, other=np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a25f4d0",
   "metadata": {},
   "source": [
    "### Repeat the process for temperature data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "05041d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature = catalog.load('temperature_train')\n",
    "temperature = validate_data(temperature, col_name='temperature', date_col_name='timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cfd435",
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.style.context('seaborn-whitegrid'):    \n",
    "    fig = plt.figure(figsize=(12, 3.54), dpi=96)\n",
    "    layout = (1, 1)\n",
    "    ax = plt.subplot2grid(layout, (0, 0))\n",
    "\n",
    "    temperature['temperature'].plot(ax=ax, alpha=0.5)\n",
    "    ax.set_xlabel('Hours')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eb81e90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature['temperature'] = global_filter(temperature['temperature'], \n",
    "                                           no_change_window=3,\n",
    "                                           allow_zero=True, \n",
    "                                           allow_negative=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c487ce0",
   "metadata": {},
   "source": [
    "No outliers found in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8c904262",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0,)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outliers_global = global_outlier_detect(temperature['temperature'], c=4)\n",
    "outliers_global[outliers_global==True].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3188cc9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outliers_local = local_outlier_detect(temperature['temperature'], c=4)\n",
    "outliers_local[outliers_local==True].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11a7afa",
   "metadata": {},
   "source": [
    "### Impute missing values in the temperature data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9c761166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing temperature values before: 32655\n"
     ]
    }
   ],
   "source": [
    "print('Number of missing temperature values before: {}'\n",
    "          .format(temperature['temperature'].isna().sum())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7454c697",
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature['temperature'] = linear_impute(temperature['temperature'], window=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eafa33b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing temperature values after: 146\n"
     ]
    }
   ],
   "source": [
    "print('Number of missing temperature values after: {}'\n",
    "          .format(temperature['temperature'].isna().sum())\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f078390",
   "metadata": {},
   "source": [
    "### Repeat the process for holiday data (if available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8c88747c",
   "metadata": {},
   "outputs": [],
   "source": [
    "holidays = None\n",
    "\n",
    "if catalog.exists('holidays_train'):\n",
    "    holidays = catalog.load('holidays_train')\n",
    "    holidays = validate_data(holidays, col_name='holiday', date_col_name='timestamp')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ace1cb",
   "metadata": {},
   "source": [
    "### Merge the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "be471ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = pd.merge_asof(consumption, temperature, left_index=True, right_index=True,\n",
    "                     direction='nearest', tolerance=pd.Timedelta('1H'))\n",
    "\n",
    "if holidays is not None:\n",
    "    holidays.index = holidays.index.map(lambda x: x.date)\n",
    "    holidays = (merged_data.index.to_series()\n",
    "                                 .map(lambda x: x.date())\n",
    "                                 .map(lambda x: holidays.iloc[:,0]\n",
    "                                 .get(x, default=np.nan))\n",
    "                                 .to_frame('holiday')\n",
    "    )\n",
    "    merged_data = merged_data.join(holidays)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f6ce07",
   "metadata": {},
   "source": [
    "### Ensure that enough training data is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d81b7d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing = merged_data[['consumption']].mask(merged_data['temperature'].isna(), np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "14dcc15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "avail_data = dict()\n",
    "\n",
    "for month_year, group in missing.groupby([lambda x: x.year, lambda x: x.month]):\n",
    "    check = check_column_values_not_null(data=group, column='consumption', mostly=0.9)\n",
    "    avail_data[month_year] = check.result['unexpected_percent']\n",
    "\n",
    "avail_data = {f'{key[0]}M{key[1]}' :val for key, val in avail_data.items()}\n",
    "avail_data = pd.DataFrame.from_dict(avail_data, orient='index', columns=['values'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2dc9d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.style.context('seaborn-whitegrid'):    \n",
    "    fig = plt.figure(figsize=(12, 3.54), dpi=96)\n",
    "    layout = (1, 1)\n",
    "    ax = plt.subplot2grid(layout, (0, 0))\n",
    "    \n",
    "    subset = avail_data.mask(avail_data['values'] <= 0.1, 0) \n",
    "    subset.plot.bar(rot=25, ax=ax, color='#C71585', legend=False)\n",
    "    \n",
    "    subset = avail_data.mask(avail_data['values'] > 0.1, 0)\n",
    "    subset.plot.bar(rot=25, ax=ax, color='#4682B4', legend=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a8c48a",
   "metadata": {},
   "source": [
    "### Impute missing values in the consumption data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a8aaecdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing consumption values before: 326\n"
     ]
    }
   ],
   "source": [
    "print('Number of missing consumption values before: {}'\n",
    "          .format(merged_data['consumption'].isna().sum())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d5347666",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed = iterative_impute(merged_data, target_name='consumption', \n",
    "                                        other_features='temperature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d5f34f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data['consumption_imputed'] = False\n",
    "\n",
    "merged_data['consumption_imputed'] = (\n",
    "        merged_data['consumption_imputed'].mask(merged_data['consumption'].isna(), other=True)\n",
    ")\n",
    "\n",
    "merged_data['consumption'] = (\n",
    "        merged_data['consumption'].mask(merged_data['consumption_imputed'], other=imputed)\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "71e8acf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing consumption values after: 0\n"
     ]
    }
   ],
   "source": [
    "print('Number of missing consumption values after: {}'\n",
    "          .format(merged_data['consumption'].isna().sum())\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de3fd69",
   "metadata": {},
   "source": [
    "### Save the data as an intermediate artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6b6819dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = catalog.save('merged_data_train', merged_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e57aaab",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e3b918",
   "metadata": {},
   "source": [
    "### Apply this workflow step on Demo Building #2\n",
    "\n",
    "The `eensight` package provides functionality for running the workflow step by step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "99fca6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from eensight.workflow.steps import PreprocessStep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c9f8bb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = load_configuration(catalog='demo_site_02')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "116f02d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = DataCatalog.from_config(catalog=cfg.catalog, \n",
    "                                  data_dir=cfg.data_dir, \n",
    "                                  ml_stages='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3e262311",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = PreprocessStep(catalog=catalog, \n",
    "                            parameters=cfg.parameters.preprocess, \n",
    "                            ml_stage='train', \n",
    "                            rebind=cfg.catalog.rebind_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6d476c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-20 14:14:01,797:INFO    : Running pre_execute\n",
      "2021-05-20 14:14:01,798:INFO    : Running execute\n",
      "2021-05-20 14:14:01,799:INFO    : Loading data from `consumption_train` (CSVDataSet)...\n",
      "2021-05-20 14:14:03,831:INFO    : Loading data from `temperature_train` (CSVDataSet)...\n",
      "2021-05-20 14:14:06,822:INFO    : Saving data to `merged_data_train` (CSVDataSet)...\n",
      "2021-05-20 14:14:06,860:INFO    : Running post_execute\n"
     ]
    }
   ],
   "source": [
    "preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00da3e3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
