{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9533d1e8",
   "metadata": {},
   "source": [
    "# The configuration approach\n",
    "\n",
    "The configuration functionality of `eensight` builds on top of the configuration functionality provided by [`Kedro`](https://github.com/quantumblacklabs/kedro). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d416cea0",
   "metadata": {},
   "source": [
    "One of the changes that `eensight` has introduced to the `Kedro` approach is a custom `ConfigLoader` (`eensight.config.OmegaConfigLoader`) that utilizes [`OmegaConf`](https://github.com/omry/omegaconf) as the backend. This makes it easy to use [variable interpolation](https://omegaconf.readthedocs.io/en/latest/usage.html#variable-interpolation) when writting the configuration files. As an example, the `globals.yaml` file contains values that can be reused in other files:  \n",
    "\n",
    "*globals.yaml:*\n",
    "```yaml\n",
    "data_root : data\n",
    "\n",
    "types:\n",
    "  csv      : pandas.CSVDataSet\n",
    "  multiple : PartitionedDataSet\n",
    "  pickle   : pickle.PickleDataSet\n",
    "\n",
    "folders:\n",
    "  raw          : 01_raw\n",
    "  intermediate : 02_intermediate\n",
    "  primary      : 03_primary\n",
    "  feature      : 04_feature\n",
    "  model_input  : 05_model_input\n",
    "  model        : 06_models\n",
    "  model_output : 07_model_output\n",
    "  report       : 08_reporting\n",
    "```\n",
    "\n",
    "... and then in *some_catalog.yaml:*\n",
    "```yaml\n",
    "site_name : demo\n",
    "\n",
    "sources:\n",
    "  train.root_input:\n",
    "    type: ${globals:types.multiple}\n",
    "    path: ${globals:data_root}/${site_name}/${globals:folders.raw}/train\n",
    "    dataset:\n",
    "      type: ${globals:types.csv}\n",
    "      load_args:\n",
    "        sep: ','\n",
    "        index_col: 0\n",
    "    filename_suffix: '.csv'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96dad9d",
   "metadata": {},
   "source": [
    "There are four (4) types of configuration files in `eensight`:\n",
    "\n",
    "- Data catalogs\n",
    "- Model configurations\n",
    "- Parameter values\n",
    "- Run command arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c99e27d",
   "metadata": {},
   "source": [
    "## Data catalogs\n",
    "\n",
    "Data catalogs are a way to describe the different datasets that are consumed and/or be produced by the `eensight` pipelines. A data catalog includes: \n",
    "\n",
    "- The name of the building/site\n",
    "\n",
    "```yaml\n",
    "site_name : demo\n",
    "```\n",
    "\n",
    "- Its location (this information is used for automatically generating holiday information) \n",
    "\n",
    "```yaml\n",
    "location:\n",
    "  country   : null  \n",
    "  province  : null \n",
    "  state     : null \n",
    "```\n",
    "\n",
    "- A mapping between specific feature names that the `eensight` functionality expects (consumption, temperature, holiday, timestamp) and the actual names used in the catalog's datasets\n",
    "\n",
    "```yaml\n",
    "rebind_names:\n",
    "  consumption : null\n",
    "  temperature : null \n",
    "  holiday     : null \n",
    "  timestamp   : null\n",
    "```\n",
    "\n",
    "- The different data sources consumed and produced by `eensight`. The information that is necessary to adequately describe a data source can be found at Kedro's documentation: https://kedro.readthedocs.io/en/stable/05_data/01_data_catalog.html    \n",
    "\n",
    "### Namespaces\n",
    "\n",
    "`eensight` supports three namespaces: `train`, `test` and `post`. \n",
    "\n",
    "`train` refers to the pre-intervention data and the pipelines that are used for building, optimizing, cross-validating and adding uncertainty information to models that predict baseline energy consumption. \n",
    "\n",
    "`test` refers to the pre-intervention data that the baseline model did not see during its fitting and optimization, and the pipelines that evaluate the baseline model on this data. \n",
    "\n",
    "`post` refers to the post-intervention data, and the pipelines that calculate cumulative energy savings and their uncertainty intervals.\n",
    "\n",
    "Adding the appropriate namespace at the beginning of a dataset's name helps automate the process of selecting and running pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b61c162",
   "metadata": {},
   "source": [
    "### Load the data catalog for the demo building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0798cc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from eensight.utils.jupyter import load_catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61794b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = load_catalog('demo')\n",
    "catalog.load('rebind_names')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a30b5a4",
   "metadata": {},
   "source": [
    "## Model configurations\n",
    "\n",
    "`eensight` is built around ensembles of localized linear regreesion models. The structure of these base models (main effects and pairwise interactions) can be defined using YAML files. These files have two sections: (a) regressors and (b) interactions.\n",
    "\n",
    "### Regressors\n",
    "\n",
    "The information for each regressor includes the name of the regressor, the name of the feature to use and encode so that to create this regressor, the type of the encoder (linear, spline or categorical), and the parameters to pass to the corresponding encoder class from `eensight.features.encode`:\n",
    "\n",
    "- IdentityEncoder\n",
    "- SplineEncoder\n",
    "- CategoricalEncoder\n",
    "\n",
    " \n",
    "\n",
    "```yaml\n",
    "regressors:\n",
    "  tow:                    # the name of the regressor\n",
    "    feature: hourofweek   # the name of the feature \n",
    "    type: categorical\n",
    "    max_n_categories: null \n",
    "    stratify_by: null \n",
    "    excluded_categories: null \n",
    "    unknown_value: null\n",
    "    min_samples_leaf: null  \n",
    "    max_features: null \n",
    "    encode_as: onehot \n",
    "    interaction_only: false\n",
    "\n",
    "  ...\n",
    "```\n",
    " \n",
    "\n",
    "### Interactions\n",
    "\n",
    "`eensight` supports pairwise interactions:\n",
    "\n",
    "- categorical by categorical\n",
    "- categorical by linear\n",
    "- categorical by spline\n",
    "- linear by linear\n",
    "- spline by spline\n",
    "\n",
    "Interactions can introduce new regressors, reuse regressors already defined in the regressors section, as well as update the parameters of regressors that are already defined:\n",
    "\n",
    "```yaml\n",
    "interactions:\n",
    "  tow, temperature:\n",
    "    tow:\n",
    "      max_n_categories: 5\n",
    "      stratify_by: temperature \n",
    "      min_samples_leaf: 20\n",
    "    temperature:\n",
    "      type: spline\n",
    "      n_knots: 4\n",
    "      degree: 2\n",
    "      strategy: quantile\n",
    "      extrapolation: constant\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eec78ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = load_catalog('demo', model='towt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8e010e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = catalog.load('model')\n",
    "print(model['main_effects'].keys())\n",
    "print(model['interactions'].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28642913",
   "metadata": {},
   "source": [
    "## Parameter values\n",
    "\n",
    "`eensight` pipelines get their parameter settings from YAML files in the *conf/base/parameters* directory.\n",
    "\n",
    "```\n",
    "conf\n",
    "│   README.md \n",
    "│\n",
    "└───base\n",
    "│   │   globals.yaml\n",
    "│   │   logging.yaml\n",
    "│   │\n",
    "│   └── parameters\n",
    "│       ├── default\n",
    "│           │   preprocess.yaml\n",
    "│           │   ...\n",
    "```\n",
    "\n",
    "Parameters are accessed and treated exactly as prescribed by the Kedro documentation: https://kedro.readthedocs.io/en/stable/04_kedro_project_setup/02_configuration.html#parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4d355a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = load_catalog('demo', model='towt', parameters='default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17eac28",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog.load('parameters')['find_outliers_for']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b4e054",
   "metadata": {},
   "source": [
    "## Run command arguments\n",
    "\n",
    "The primary way of using `eensight` is through the command line:\n",
    "\n",
    "<code>python -m eensight </code>\n",
    "\n",
    "The command line functionality uses the [Hydra framework](https://hydra.cc/):\n",
    "\n",
    "```python\n",
    "from .settings import DEFAULT_CATALOG, DEFAULT_MODEL, DEFAULT_PARAMETERS, PROJECT_PATH\n",
    "\n",
    "@hydra.main(config_path=\"hydra\", config_name=\"run_config\")\n",
    "def run(cfg: DictConfig):\n",
    "    cfg = OmegaConf.to_container(cfg)\n",
    "\n",
    "    runner = cfg.get(\"runner\") or \"SequentialRunner\"\n",
    "    runner_class = load_obj(runner, \"kedro.runner\")\n",
    "\n",
    "    parameters = cfg.get(\"parameter_config\") or DEFAULT_PARAMETERS\n",
    "    catalog = cfg.get(\"catalog_config\") or DEFAULT_CATALOG\n",
    "    model = cfg.get(\"model_config\") or DEFAULT_MODEL\n",
    "    ...\n",
    "```\n",
    "\n",
    "\n",
    "The `run_config.yaml` file includes all the availabe command line options:\n",
    "\n",
    "```yaml\n",
    "\n",
    "catalog # The name of the catalog configuration file to load \n",
    "model # The name of the model configuration file to load\n",
    "parameters # The name of the parameters configuration file to load\n",
    "pipeline # The name of the modular pipeline to run\n",
    "runner # The runner that you want to run the pipeline with\n",
    "async # If load and save node inputs and outputs should be done asynchronously with threads\n",
    "env # Kedro configuration environment name\n",
    "from_inputs # A list of dataset names which should be used as a starting point\n",
    "to_outputs # A list of dataset names which should be used as an end point\n",
    "from_nodes # A list of node (pipeline step) names which should be used as a starting point\n",
    "to_nodes # A list of node names which should be used as an end point \n",
    "nodes # A list with node names. The `run` function will run only these nodes\n",
    "tags # List of tags. Construct a pipeline from nodes having any of these tags\n",
    "load_versions # A mapping between dataset names and versions to load\n",
    "params # These values will override the values in the `parameters` configuration file \n",
    "```\n",
    "\n",
    "`eensight` uses its onw `CustomContext` (that extends `KedroContext`) so that the selected catalog, model and parameter configuration files are passed to the `OmegaConfigLoader`, and become available in the application's [data catalog object](https://kedro.readthedocs.io/en/stable/kedro.io.DataCatalog.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe06dfc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
