{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9533d1e8",
   "metadata": {},
   "source": [
    "# The configuration approach\n",
    "\n",
    "`eensight` is a [Kedro](https://github.com/quantumblacklabs/kedro)-based application. Accordingly, the configuration functionality of `eensight` builds on top of the configuration functionality provided by Kedro."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d416cea0",
   "metadata": {},
   "source": [
    "One of the changes that `eensight` has introduced to the Kedro's standard approach is a custom `ConfigLoader` (`eensight.config.OmegaConfigLoader`) that utilizes [`OmegaConf`](https://github.com/omry/omegaconf) as backend. This makes it easy to use [variable interpolation](https://omegaconf.readthedocs.io/en/latest/usage.html#variable-interpolation) when writting the configuration files. As an example, the `globals.yaml` file contains values that can be reused in other files:  \n",
    "\n",
    "*globals.yaml:*\n",
    "```yaml\n",
    "data_root : data\n",
    "\n",
    "types:\n",
    "  csv      : pandas.CSVDataSet\n",
    "  multiple : PartitionedDataSet\n",
    "  pickle   : pickle.PickleDataSet\n",
    "\n",
    "folders:\n",
    "  raw          : 01_raw\n",
    "  intermediate : 02_intermediate\n",
    "  primary      : 03_primary\n",
    "  feature      : 04_feature\n",
    "  model_input  : 05_model_input\n",
    "  model        : 06_models\n",
    "  model_output : 07_model_output\n",
    "  report       : 08_reporting\n",
    "```\n",
    "\n",
    "... and then in *some_catalog.yaml:*\n",
    "```yaml\n",
    "site_name : demo\n",
    "\n",
    "sources:\n",
    "  train.root_input:\n",
    "    type: ${globals:types.multiple}\n",
    "    path: ${globals:data_root}/${site_name}/${globals:folders.raw}/train\n",
    "    dataset:\n",
    "      type: ${globals:types.csv}\n",
    "      load_args:\n",
    "        sep: ','\n",
    "        index_col: 0\n",
    "    filename_suffix: '.csv'\n",
    "```\n",
    "\n",
    "It is not necessary to use variable interpolation in `eensight`'s configuration files, but it simplifies the process of writting them. One could have also defined *some_catalog.yaml* as: \n",
    "\n",
    "```yaml\n",
    "site_name : demo\n",
    "\n",
    "sources:\n",
    "  train.root_input:\n",
    "    type: PartitionedDataSet\n",
    "    path: data/demo/01_raw/train\n",
    "    dataset:\n",
    "      type: pandas.CSVDataSet\n",
    "      load_args:\n",
    "        sep: ','\n",
    "        index_col: 0\n",
    "    filename_suffix: '.csv'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96dad9d",
   "metadata": {},
   "source": [
    "There are four (4) types of configuration files in `eensight`:\n",
    "\n",
    "- Data catalogs\n",
    "- Model configurations\n",
    "- Parameter values\n",
    "- Run command arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c99e27d",
   "metadata": {},
   "source": [
    "## Data catalogs\n",
    "\n",
    "Data catalogs are a way to describe the different datasets that are consumed and/or produced by the `eensight` pipelines. A data catalog includes: \n",
    "\n",
    "- The name of the building/site\n",
    "\n",
    "example:\n",
    "```yaml\n",
    "site_name : some_site\n",
    "```\n",
    "\n",
    "- Its location (this information is used for automatically generating holiday information) \n",
    "\n",
    "example:\n",
    "```yaml\n",
    "location:\n",
    "  country   : Italy  \n",
    "  province  : null \n",
    "  state     : null \n",
    "```\n",
    "\n",
    "- A mapping between specific feature names that the `eensight` functionality expects (consumption, temperature, holiday, timestamp) and the actual names used in the catalog's datasets\n",
    "\n",
    "example:\n",
    "```yaml\n",
    "rebind_names:\n",
    "  consumption : eload\n",
    "  temperature : temp \n",
    "  holiday     : null \n",
    "  timestamp   : dates\n",
    "```\n",
    "\n",
    "- The different data sources consumed and produced by `eensight`. The information that is necessary to adequately describe a data source can be found at Kedro's documentation: https://kedro.readthedocs.io/en/stable/05_data/01_data_catalog.html    \n",
    "\n",
    "### Namespaces\n",
    "\n",
    "`eensight` supports three namespaces: `train`, `test` and `post`. \n",
    "\n",
    "`train` refers to the pre-intervention data and the pipelines that are used for building, optimizing, cross-validating and adding uncertainty information to models that predict baseline energy consumption. \n",
    "\n",
    "`test` refers to the pre-intervention data that the baseline model did not see during its fitting and optimization, and the pipelines that evaluate the baseline model on this data. \n",
    "\n",
    "`post` refers to the post-intervention data, and the pipelines that calculate cumulative energy savings and their uncertainty intervals.\n",
    "\n",
    "Adding the appropriate namespace at the beginning of a dataset's name helps automate the process of selecting and running pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b61c162",
   "metadata": {},
   "source": [
    "### Load the data catalog for the demo building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0798cc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from eensight.utils.jupyter import load_catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4fe6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = load_catalog('demo')\n",
    "catalog.load('rebind_names')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a30b5a4",
   "metadata": {},
   "source": [
    "## Model configurations\n",
    "\n",
    "`eensight` is built around ensembles of localized linear regression models. The structure of these base models can be defined using YAML files. These files have three sections: (a) added features, (b) regressors and (c) interactions.\n",
    "\n",
    "### Added features\n",
    "\n",
    "The information in this section is passed to one of the feature generators in `eensight.features.generate`:\n",
    "\n",
    "- `TrendFeatures`\n",
    "- `DatetimeFeatures`\n",
    "- `CyclicalFeatures`\n",
    "\n",
    "```yaml\n",
    "add_features:\n",
    "  time:            # the name of the generator\n",
    "    feature: null  # the name of the feature (if null, it is the input's index)\n",
    "    type: datetime\n",
    "    remainder: passthrough\n",
    "    subset: month, hourofweek\n",
    "```\n",
    "\n",
    "All feature generators create time-related features, and their output is a pandas `DataFrame`. Also, they all have two common parameters:\n",
    "\n",
    "```yaml\n",
    "remainder : str, :type : {'drop', 'passthrough'}, default='passthrough'\n",
    "    By specifying `remainder='passthrough'`, all the remaining columns of the\n",
    "    input dataset will be automatically passed through (concatenated with the\n",
    "    output of the transformer).\n",
    "replace : bool, default=False\n",
    "    Specifies whether replacing an existing column with the same name is allowed\n",
    "    (when `remainder=passthrough`).\n",
    "```\n",
    "\n",
    "\n",
    "### Regressors\n",
    "\n",
    "The information for each regressor includes its name, the name of the feature to use and encode so that to create this regressor, the type of the encoder (linear, spline or categorical), and the parameters to pass to the corresponding encoder class from `eensight.features.encode`:\n",
    "\n",
    "- `IdentityEncoder`\n",
    "- `SplineEncoder`\n",
    "- `CategoricalEncoder`\n",
    "\n",
    " \n",
    "\n",
    "```yaml\n",
    "regressors:\n",
    "  month:                   # the name of the regressor\n",
    "    feature: month         # the name of the feature \n",
    "    type: categorical\n",
    "    max_n_categories: null\n",
    "    encode_as: onehot \n",
    "    interaction_only: false\n",
    "    \n",
    "  tow:                     # the name of the regressor\n",
    "    feature: hourofweek    # the name of the feature \n",
    "    type: categorical\n",
    "    max_n_categories: null \n",
    "    encode_as: onehot \n",
    "    interaction_only: false\n",
    "\n",
    "```\n",
    " \n",
    "\n",
    "### Interactions\n",
    "\n",
    "`eensight` supports pairwise interactions between:\n",
    "\n",
    "- categorical and categorical encoders\n",
    "- categorical and linear encoders\n",
    "- categorical and spline encoders\n",
    "- linear and linear encoders\n",
    "- spline and spline encoders\n",
    "\n",
    "Interactions can introduce new regressors, reuse regressors already defined in the regressors section, as well as alter the parameters of regressors that are already defined in the regressors section:\n",
    "\n",
    "```yaml\n",
    "interactions:\n",
    "  tow, temperature:\n",
    "    tow:\n",
    "      max_n_categories: 5\n",
    "      stratify_by: temperature \n",
    "      min_samples_leaf: 20\n",
    "    temperature:\n",
    "      type: spline\n",
    "      n_knots: 4\n",
    "      degree: 2\n",
    "      strategy: quantile\n",
    "      extrapolation: constant\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eec78ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = load_catalog('demo', model='towt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca53298",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = catalog.load('model')\n",
    "print(model['add_features'].keys())\n",
    "print(model['main_effects'].keys())\n",
    "print(model['interactions'].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28642913",
   "metadata": {},
   "source": [
    "## Parameter values\n",
    "\n",
    "`eensight` pipelines get their parameter settings from YAML files in the *conf/base/parameters* directory.\n",
    "\n",
    "```\n",
    "conf\n",
    "│   README.md \n",
    "│\n",
    "└───base\n",
    "│   │   globals.yaml\n",
    "│   │   logging.yaml\n",
    "│   │\n",
    "│   └── parameters\n",
    "│       ├── default\n",
    "│           │   preprocess.yaml\n",
    "│           │   ...\n",
    "```\n",
    "\n",
    "Parameters are accessed and treated exactly as prescribed by the Kedro documentation: https://kedro.readthedocs.io/en/stable/04_kedro_project_setup/02_configuration.html#parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4d355a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = load_catalog('demo', model='towt', parameters='default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb1e823",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog.load('parameters')['find_outliers_for']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b4e054",
   "metadata": {},
   "source": [
    "## Run command arguments\n",
    "\n",
    "The primary way of using `eensight` is through the command line:\n",
    "\n",
    "<code>python -m eensight </code>\n",
    "\n",
    "The command line functionality uses the [Hydra framework](https://hydra.cc/):\n",
    "\n",
    "*from eensight.cli.py:*\n",
    "\n",
    "```python\n",
    "from .settings import DEFAULT_CATALOG, DEFAULT_MODEL, DEFAULT_PARAMETERS, PROJECT_PATH\n",
    "\n",
    "@hydra.main(config_path=\"hydra\", config_name=\"run_config\")\n",
    "def run(cfg: DictConfig):\n",
    "    cfg = OmegaConf.to_container(cfg)\n",
    "\n",
    "    runner = cfg.get(\"runner\") or \"SequentialRunner\"\n",
    "    runner_class = load_obj(runner, \"kedro.runner\")\n",
    "\n",
    "    parameters = cfg.get(\"parameter_config\") or DEFAULT_PARAMETERS\n",
    "    catalog = cfg.get(\"catalog_config\") or DEFAULT_CATALOG\n",
    "    model = cfg.get(\"model_config\") or DEFAULT_MODEL\n",
    "    ...\n",
    "```\n",
    "\n",
    "\n",
    "The `eensight/hydra/run_config.yaml` file includes all the availabe command line options:\n",
    "\n",
    "| Argument \t| Description \t|\n",
    "|---\t|---\t|\n",
    "| catalog \t| The name of the catalog configuration file to load \t|\n",
    "| model \t| The name of the model configuration file to load \t|\n",
    "| parameters \t| The name of the parameters configuration file to load \t|\n",
    "| pipeline \t| The name of the modular pipeline to run \t|\n",
    "| runner \t| The runner that you want to run the pipeline with \t|\n",
    "| async \t| If load and save node inputs and outputs should be done asynchronously with threads \t|\n",
    "| env \t| Kedro configuration environment name \t|\n",
    "| from_inputs \t| A list of dataset names which should be used as a starting point \t|\n",
    "| to_outputs \t| A list of dataset names which should be used as an end point \t|\n",
    "| from_nodes \t| A list of node (pipeline step) names which should be used as a starting point \t|\n",
    "| to_nodes \t| A list of node names which should be used as an end point \t|\n",
    "| nodes \t| A list with node names. The `run` function will run only these nodes \t|\n",
    "| tags \t| List of tags. Construct a pipeline from nodes having any of these tags \t|\n",
    "| load_versions \t| A mapping between dataset names and versions to load \t|\n",
    "| params \t| These values will override the values in the `parameters` configuration file \t|\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c6fdfd",
   "metadata": {},
   "source": [
    "`eensight` uses its onw `CustomContext` (that extends `KedroContext`) so that the selected catalog, model and parameter configuration files are passed to the `OmegaConfigLoader`, and become available in the application's [data catalog object](https://kedro.readthedocs.io/en/stable/kedro.io.DataCatalog.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3850ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
