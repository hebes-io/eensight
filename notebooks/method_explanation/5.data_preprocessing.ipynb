{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30997a83",
   "metadata": {},
   "source": [
    "# The preprocessing pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4461ba74",
   "metadata": {},
   "source": [
    "## The goal of the preprocessing pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600d4b53",
   "metadata": {},
   "source": [
    "The data preprocessing pipeline assumes that energy consumption and outdoor air temperature is the only data that is available for M&V. We consider an energy consumption and outdoor air temperature dataset valid if:\n",
    "    \n",
    "    \n",
    "1. **There are no duplicate values in the dataset’s timestamps**. Duplicate timestamps are treated separately for energy consumption and for temperature data. In both cases, if the range of the energy consumption or temperature values that share a timestamp is short – according to a user-defined threshold– they are replaced by their average. Otherwise, they are treated as missing values.\n",
    "\n",
    "\n",
    "2. **There are no missing values in the dataset’s timestamps**. If there are missing timestamps, they are added and the respective data is treated as missing values.\n",
    "\n",
    "\n",
    "3. **Potential outliers are identified and marked**. Outlier detection is carried out separately for energy consumption and for temperature data. \n",
    "\n",
    "\n",
    "4. **There is enough data available for the energy consumption of the building under study**. Baseline energy consumption data must cover at least one full year before any energy efficiency intervention. In addition, and adopting the data requirements of the [CalTRACK](https://www.caltrack.org/) set of methods, data must be available for over 90% of hours in each calendar month – ***after excluding the potential outliers***.\n",
    "\n",
    "\n",
    "5. **There are no missing values in the outdoor air temperature data**. If temperature data is missing, the missing values are imputed. The outdoor air temperature changes smoothly from one hour to the next, so interpolating over a 6-hour window around a missing observation is a sensible approach for imputation. This is in line with CalTRACK's requirement that temperature data may not be missing for more than six (6) consecutive hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "638745a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b94c9ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "pd.plotting.register_matplotlib_converters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be2fb885",
   "metadata": {},
   "outputs": [],
   "source": [
    "from eensight.utils.jupyter import load_catalog\n",
    "from eensight.pipelines.preprocessing import validate_input_data\n",
    "from eensight.pipelines.preprocessing import (global_filter, global_outlier_detect, \n",
    "                                              local_outlier_detect)\n",
    "\n",
    "from eensight.pipelines.preprocessing import decompose_consumption, decompose_temperature\n",
    "from eensight.pipelines.preprocessing.validation import check_column_values_not_null\n",
    "from eensight.pipelines.preprocessing import linear_impute"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f55258",
   "metadata": {},
   "source": [
    "## Load the data catalog for the demo building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6dd3cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = load_catalog('demo')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56aa412e",
   "metadata": {},
   "source": [
    "## Preprocess the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6cde71a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input = catalog.load('train.root_input')\n",
    "merged_data = validate_input_data(train_input, rebind_names=catalog.load('rebind_names'), \n",
    "                                          location=catalog.load('location'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e3861c",
   "metadata": {},
   "source": [
    "### Select the consumption data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e850f0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "consumption =  merged_data['consumption']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5940dd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.style.context('seaborn-whitegrid'):    \n",
    "    fig = plt.figure(figsize=(12, 3.54), dpi=96)\n",
    "    layout = (1, 1)\n",
    "    ax = plt.subplot2grid(layout, (0, 0))\n",
    "\n",
    "    consumption.loc[consumption.notna()].plot(ax=ax, alpha=0.5)\n",
    "    ax.set_xlabel('Hours')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7192561",
   "metadata": {},
   "source": [
    "### Outlier identification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39a5f8c",
   "metadata": {},
   "source": [
    "The proposed approach for outlier identification is outlined next:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813d68f7",
   "metadata": {},
   "source": [
    "#### Step 1: Global filter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef112940",
   "metadata": {},
   "source": [
    "The first step screens for non-physically plausible values as well as unlikely values in the data. \n",
    "\n",
    "For power consumption data, negative and zero values are filtered out. \n",
    "\n",
    "For both consumption and temperature data, values that are at least 10 times larger than the median value are also removed. The threshold of ten times the median value aims at removing the most extreme outliers. \n",
    "\n",
    "Furthermore, long streaks of constant values are filtered out as well (here *long* is defined in hours by `no_change_window`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c7444767",
   "metadata": {},
   "outputs": [],
   "source": [
    "consumption = global_filter(consumption, \n",
    "                            no_change_window=3,\n",
    "                            allow_zero=False, \n",
    "                            allow_negative=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e46a57",
   "metadata": {},
   "source": [
    "#### Step 2: Seasonal filter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c107308a",
   "metadata": {},
   "source": [
    "The second step captures the seasonal cycle of the data through a trend and seasonality decomposition approach that utilizes a Fourier series expansion of the form:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e36368",
   "metadata": {},
   "source": [
    "$$y(t)=\\alpha+bt+\\sum_{n=1}^{N} (\\alpha_n\\cos(\\frac{2πnt}{P}) + b_n\\sin(\\frac{2πnt}{P}))$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04e4652",
   "metadata": {},
   "source": [
    "where:\n",
    "\n",
    "$\\alpha$    is the offset of the linear trend\n",
    "\n",
    "$b$    is the slope of the linear trend\n",
    "\n",
    "$t$    is the day since a pre-specified epoch. For hourly data, $t$ will take decimal number values.\n",
    "\n",
    "$N$    is a parameter that controls the flexibility of the expansion. Suggested values are N=4 for daily seasonality, N=10 for yearly seasonality (see [Taylor S. J. and Letham B. (2018) \"Forecasting at scale,\" The American Statistician 72(1), pp. 37-45](https://peerj.com/preprints/3190/))\n",
    "\n",
    "$P$    is the length of the seasonality: P=1 for daily seasonality, P=365.25 for yearly seasonality. For energy consumption data, we fit a different daily seasonality component for each day of the week.  \n",
    "\n",
    "$\\alpha_n, b_n$\tRegression coefficients for the Fourier series expansion terms.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14842a46",
   "metadata": {},
   "source": [
    "The reason for applying seasonal decomposition before outlier identification can be seen in the figure below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "c879c8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_pdf(x, data, distribution=stats.norm):\n",
    "    # fit dist to data\n",
    "    params = distribution.fit(data)\n",
    "\n",
    "    # Separate parts of parameters\n",
    "    arg = params[:-2]\n",
    "    loc = params[-2]\n",
    "    scale = params[-1]\n",
    "\n",
    "    # Calculate fitted PDF and error with fit in distribution\n",
    "    pdf = distribution.pdf(x, loc=loc, scale=scale, *arg)\n",
    "    return params, pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37b8272",
   "metadata": {},
   "outputs": [],
   "source": [
    "consumption_ = consumption.dropna().values\n",
    "x_d = np.linspace(consumption_.min(), consumption_.max(), 2000)\n",
    "params, pdf = fit_pdf(x_d, consumption_)\n",
    "\n",
    "with plt.style.context('seaborn-whitegrid'):    \n",
    "    fig = plt.figure(figsize=(12, 3.54), dpi=96)\n",
    "    layout = (1, 1)\n",
    "    ax = plt.subplot2grid(layout, (0, 0))\n",
    "    \n",
    "    consumption.plot(kind='hist', bins=100, density=True, alpha=0.3, ax=ax)\n",
    "    pd.Series(pdf, x_d).plot(ax=ax)\n",
    "    \n",
    "    ax.legend(['Fitted Normal distribution', 'Actual distribution of power consumption'], \n",
    "              frameon=True, shadow=True, fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edaf1419",
   "metadata": {},
   "source": [
    "Since seasonality leads to multimodal distributions, methods that rely on the assumption that the data follows a Normal distribution – such as simple three-sigma rules, the Grubbs test or the Extreme Studentized Deviate (ESD) test  – should generally be used only ***after*** a seasonal filter has been applied to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "58effbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = decompose_consumption(consumption.dropna().to_frame(\"consumption\"),\n",
    "                                return_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d9c481",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.model.composer_.component_names_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "6b886218",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = results.transformed['yhat']\n",
    "resid = results.transformed['resid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8257b0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'CV(RMSE): {np.sqrt(np.mean(resid**2)) / np.mean(consumption)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4f6456",
   "metadata": {},
   "source": [
    "The next plot shows the actual and the predicted power consumption for the first and the last month of 2016:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b284ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.style.context('seaborn-whitegrid'):    \n",
    "    fig = plt.figure(figsize=(12, 6), dpi=96)\n",
    "    layout = (2, 1)\n",
    "    ax1 = plt.subplot2grid(layout, (0, 0))\n",
    "    ax2 = plt.subplot2grid(layout, (1, 0))\n",
    "\n",
    "    start = datetime(2016, 1, 1, 0)\n",
    "    end = datetime(2016, 2, 1, 0)\n",
    "    consumption.loc[start:end].plot(ax=ax1, alpha=0.6)\n",
    "    pred.loc[start:end].plot(ax=ax1, alpha=0.4)\n",
    "    ax1.set_xlabel('Hours')\n",
    "    ax1.legend(['Power consumption', 'Seasonal prediction'], frameon=True, shadow=True)\n",
    "    \n",
    "    start = datetime(2016, 12, 1, 0)\n",
    "    end = datetime(2017, 1, 1, 0)\n",
    "    consumption.loc[start:end].plot(ax=ax2, alpha=0.6)\n",
    "    pred.loc[start:end].plot(ax=ax2, alpha=0.4)\n",
    "    ax2.set_xlabel('Hours')\n",
    "    ax2.legend(['Power consumption', 'Seasonal prediction'], frameon=True, shadow=True)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ebe794",
   "metadata": {},
   "source": [
    "The next plot shows the distribution of the residuals when subtracting the actual from the predicted power consumption. The distribution of the residuals resembles a Student’s t distribution and, hence, it is easier to work with for detecting outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9806003",
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals_ = resid.dropna()\n",
    "x_d = np.linspace(residuals_.min(), residuals_.max(), 2000)\n",
    "\n",
    "_, pdf_t = fit_pdf(x_d, residuals_, distribution=stats.t)\n",
    "\n",
    "\n",
    "with plt.style.context('seaborn-whitegrid'):    \n",
    "    fig = plt.figure(figsize=(12, 3.54), dpi=96)\n",
    "    layout = (1, 1)\n",
    "    ax = plt.subplot2grid(layout, (0, 0))\n",
    "    \n",
    "    resid.plot(kind='hist', bins=100, density=True, alpha=0.3, ax=ax)\n",
    "    pd.Series(pdf_t, x_d).plot(ax=ax)\n",
    "    \n",
    "    ax.legend(['Fitted Student\\'s t distribution', 'Distribution of residuals'], \n",
    "              frameon=True, shadow=True, fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645a49dd",
   "metadata": {},
   "source": [
    "#### Step 3: Global outlier detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5376cb4",
   "metadata": {},
   "source": [
    "The third step of the outlier detection process identifies observations in the available dataset as potential outliers if the value of their corresponding residuals lies outside the range defined by:\n",
    "\n",
    "$$[median^{all} - c\\times mad^{all}, median^{all} + c\\times mad^{all}]$$\n",
    "\n",
    "where:\n",
    "\n",
    "$median^{all}$ is the median of all the residual values\n",
    "\n",
    "$mad^{all}$ is the median absolute deviation of all the residual values\n",
    "\n",
    "$c$ is a user defined parameter (suggested value is 5).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "d2a32a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers_global = global_outlier_detect(resid, c=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857d5680",
   "metadata": {},
   "source": [
    "The next plot shows the potential outliers in power consumption identified using the global outlier detection for January, August, first 5 days of September and December 2016:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af00b836",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = consumption.loc[consumption.index.isin(outliers_global[outliers_global].index)]\n",
    "\n",
    "with plt.style.context('seaborn-whitegrid'):    \n",
    "    fig = plt.figure(figsize=(12, 8), dpi=96)\n",
    "    layout = (3, 1)\n",
    "    ax1 = plt.subplot2grid(layout, (0, 0))\n",
    "    ax2 = plt.subplot2grid(layout, (1, 0))\n",
    "    ax3 = plt.subplot2grid(layout, (2, 0))\n",
    "    \n",
    "    start = datetime(2016, 1, 1, 0)\n",
    "    end = datetime(2016, 2, 1, 0)\n",
    "    consumption.loc[start:end].plot(ax=ax1, alpha=0.6)\n",
    "    try:\n",
    "        subset.loc[start:end].plot(ax=ax1, style='o', ms=4, c='red', alpha=0.4)\n",
    "    except IndexError:\n",
    "        pass \n",
    "    \n",
    "    start = datetime(2016, 8, 1, 0)\n",
    "    end = datetime(2016, 9, 6, 0)\n",
    "    consumption.loc[start:end].plot(ax=ax2, alpha=0.6)\n",
    "    try:\n",
    "        subset.loc[start:end].plot(ax=ax2, style='o', ms=4, c='red', alpha=0.4)\n",
    "    except IndexError:\n",
    "        pass\n",
    "    \n",
    "    start = datetime(2016, 12, 1, 0)\n",
    "    end = datetime(2017, 1, 1, 0)\n",
    "    consumption.loc[start:end].plot(ax=ax3, alpha=0.6)\n",
    "    try:\n",
    "        subset.loc[start:end].plot(ax=ax3, style='o', ms=4, c='red', alpha=0.4)\n",
    "    except IndexError:\n",
    "        pass\n",
    "    ax3.set_xlabel('Hours')\n",
    "    \n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4ca931",
   "metadata": {},
   "source": [
    "#### Step 4: Local outlier detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8110e7d2",
   "metadata": {},
   "source": [
    "The final step of the outlier detection process retains from the outliers identified in the previous step only those that can be characterised as outliers when we also compare their values with the observations in the same day of the year. \n",
    "\n",
    "The rationale for this approach can be explained by looking at the next plot, which shows the actual and the predicted power consumption during the first two (2) weeks of 2016 in the dataset. An important observation from the plot is that the distance from the seasonal model’s predictions is not by itself enough for detecting outliers when the whole day is misrepresented by the model (here a holiday is treated as a normal day)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a80e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime(2016, 1, 1, 0)\n",
    "end = datetime(2016, 1, 1, 0) + timedelta(days=14)\n",
    "\n",
    "with plt.style.context('seaborn-whitegrid'):    \n",
    "    fig = plt.figure(figsize=(12, 3.54), dpi=96)\n",
    "    layout = (1, 1)\n",
    "    ax = plt.subplot2grid(layout, (0, 0))\n",
    "\n",
    "    consumption.loc[start:end].plot(ax=ax, alpha=0.8)\n",
    "    pred.loc[start:end].plot(ax=ax, alpha=0.4)\n",
    "    \n",
    "    ax.set_ylim(top=7000)\n",
    "    ax.annotate(' First day of year ', xy=(datetime(2016, 1, 1, 12), 2200),  xycoords='data',\n",
    "             xytext=(40, 140), textcoords='offset points',\n",
    "             size=13, ha='center', va=\"center\",\n",
    "             bbox=dict(boxstyle=\"round\", alpha=0.3),\n",
    "             arrowprops=dict(arrowstyle=\"wedge,tail_width=0.5\", alpha=0.3))\n",
    "    \n",
    "    ax.set_xlabel('Hours')\n",
    "    ax.legend(['Power consumption', 'Seasonal prediction'], frameon=True, shadow=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c50ee24",
   "metadata": {},
   "source": [
    "Accordingly, the observations in the available dataset are marked as potential outliers if the value of their corresponding residuals lies outside the range defined by:\n",
    "\n",
    "$$[median^{day} - c\\times mad^{day}, median^{day} + c\\times mad^{day}]$$\n",
    "\n",
    "where:\n",
    "\n",
    "$median^{day}$ is the median of all the residual values in the corresponding day\n",
    "\n",
    "$mad^{day}$ is the median absolute deviation of all the residual values in the corresponding day\n",
    "\n",
    "$c$ is a user defined parameter (suggested value is 5).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6159c8ff",
   "metadata": {},
   "source": [
    "This step is parameterised by the minimum percentage of observations `min_samples` that must be available for any given day so that to take the daily statistics into account. If the number of the available observations is lower than this threshold, only the global outlier detection results are considered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "574940c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers_local = local_outlier_detect(resid, min_samples=0.6, c=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f197e92",
   "metadata": {},
   "source": [
    "The next plot shows the potential outliers in power consumption identified using the local outlier detection for January, August, first 5 days of September and December 2016:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e109f590",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = consumption.loc[consumption.index.isin(outliers_local[outliers_local].index)]\n",
    "\n",
    "with plt.style.context('seaborn-whitegrid'):    \n",
    "    fig = plt.figure(figsize=(12, 8), dpi=96)\n",
    "    layout = (3, 1)\n",
    "    ax1 = plt.subplot2grid(layout, (0, 0))\n",
    "    ax2 = plt.subplot2grid(layout, (1, 0))\n",
    "    ax3 = plt.subplot2grid(layout, (2, 0))\n",
    "    \n",
    "    start = datetime(2016, 1, 1, 0)\n",
    "    end = datetime(2016, 2, 1, 0)\n",
    "    consumption.loc[start:end].plot(ax=ax1, alpha=0.6)\n",
    "    try:\n",
    "        subset.loc[start:end].plot(ax=ax1, style='o', ms=4, c='red', alpha=0.4)\n",
    "    except IndexError:\n",
    "        pass\n",
    "    \n",
    "    start = datetime(2016, 8, 1, 0)\n",
    "    end = datetime(2016, 9, 6, 0)\n",
    "    consumption.loc[start:end].plot(ax=ax2, alpha=0.6)\n",
    "    try:\n",
    "        subset.loc[start:end].plot(ax=ax2, style='o', ms=4, c='red', alpha=0.4)\n",
    "    except IndexError:\n",
    "        pass\n",
    "    \n",
    "    start = datetime(2016, 12, 1, 0)\n",
    "    end = datetime(2017, 1, 1, 0)\n",
    "    consumption.loc[start:end].plot(ax=ax3, alpha=0.6)\n",
    "    try:\n",
    "        subset.loc[start:end].plot(ax=ax3, style='o', ms=4, c='red', alpha=0.4)\n",
    "    except IndexError:\n",
    "        pass\n",
    "    ax3.set_xlabel('Hours')\n",
    "    \n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8772dbb",
   "metadata": {},
   "source": [
    "For an observation to be marked as an outlier, both global and local results must agree. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "64e74521",
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers = np.logical_and(outliers_global, outliers_local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f263c91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = consumption.loc[consumption.index.isin(outliers[outliers].index)]\n",
    "\n",
    "with plt.style.context('seaborn-whitegrid'):    \n",
    "    fig = plt.figure(figsize=(12, 8), dpi=96)\n",
    "    layout = (3, 1)\n",
    "    ax1 = plt.subplot2grid(layout, (0, 0))\n",
    "    ax2 = plt.subplot2grid(layout, (1, 0))\n",
    "    ax3 = plt.subplot2grid(layout, (2, 0))\n",
    "    \n",
    "    start = datetime(2016, 1, 1, 0)\n",
    "    end = datetime(2016, 2, 1, 0)\n",
    "    consumption.loc[start:end].plot(ax=ax1, alpha=0.6)\n",
    "    try:\n",
    "        subset.loc[start:end].plot(ax=ax1, style='o', ms=4, c='red', alpha=0.4)\n",
    "    except IndexError:\n",
    "        pass\n",
    "    \n",
    "    start = datetime(2016, 8, 1, 0)\n",
    "    end = datetime(2016, 9, 6, 0)\n",
    "    consumption.loc[start:end].plot(ax=ax2, alpha=0.6)\n",
    "    try:\n",
    "        subset.loc[start:end].plot(ax=ax2, style='o', ms=4, c='red', alpha=0.4)\n",
    "    except IndexError:\n",
    "        pass\n",
    "    \n",
    "    start = datetime(2016, 12, 1, 0)\n",
    "    end = datetime(2017, 1, 1, 0)\n",
    "    consumption.loc[start:end].plot(ax=ax3, alpha=0.6)\n",
    "    try:\n",
    "        subset.loc[start:end].plot(ax=ax3, style='o', ms=4, c='red', alpha=0.4)\n",
    "    except IndexError:\n",
    "        pass\n",
    "    ax3.set_xlabel('Hours')\n",
    "    \n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996fe564",
   "metadata": {},
   "source": [
    "The next plot shows the potential outliers identified in the whole consumption dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b59bb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.style.context('seaborn-whitegrid'):    \n",
    "    fig = plt.figure(figsize=(12, 3.54), dpi=96)\n",
    "    layout = (1, 1)\n",
    "    ax = plt.subplot2grid(layout, (0, 0))\n",
    "    \n",
    "    consumption.plot(ax=ax, alpha=0.4, style='.', ms=2)\n",
    "    \n",
    "    subset = consumption.loc[consumption.index.isin(outliers[outliers].index)]\n",
    "    subset.plot(ax=ax, style='o', ms=3, c='red')\n",
    "    \n",
    "    ax.set_xlabel('Hours')\n",
    "    ax.legend(['Power consumption', 'Potential outliers'], frameon=True, shadow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "b060c8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data['consumption'] = consumption\n",
    "merged_data['consumption_outlier'] = outliers\n",
    "merged_data['consumption_outlier'] = merged_data['consumption_outlier'].fillna(value=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a25f4d0",
   "metadata": {},
   "source": [
    "### Repeat the process for temperature data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48580c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature = merged_data['temperature']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8369899",
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.style.context('seaborn-whitegrid'):    \n",
    "    fig = plt.figure(figsize=(12, 3.54), dpi=96)\n",
    "    layout = (1, 1)\n",
    "    ax = plt.subplot2grid(layout, (0, 0))\n",
    "\n",
    "    temperature.loc[temperature.notna()].plot(ax=ax, alpha=0.5)\n",
    "    ax.set_xlabel('Hours')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "eb81e90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature = global_filter(temperature, \n",
    "                            no_change_window=3,\n",
    "                            allow_zero=True, \n",
    "                            allow_negative=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c01d69",
   "metadata": {},
   "source": [
    "We apply seasonal decomposition on the temperature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "0efd693b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = decompose_temperature(temperature.dropna().to_frame(\"temperature\"),\n",
    "                                return_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19682738",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.model.composer_.component_names_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "30b245a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "resid = results.transformed['resid']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f76dbde",
   "metadata": {},
   "source": [
    "The distribution of the residuals resembles a Student’s t distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ac7c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals_ = resid.dropna()\n",
    "x_d = np.linspace(residuals_.min(), residuals_.max(), 2000)\n",
    "\n",
    "_, pdf_t = fit_pdf(x_d, residuals_, distribution=stats.t)\n",
    "\n",
    "\n",
    "with plt.style.context('seaborn-whitegrid'):    \n",
    "    fig = plt.figure(figsize=(12, 3.54), dpi=96)\n",
    "    layout = (1, 1)\n",
    "    ax = plt.subplot2grid(layout, (0, 0))\n",
    "    \n",
    "    resid.plot(kind='hist', bins=100, density=True, alpha=0.3, ax=ax)\n",
    "    pd.Series(pdf_t, x_d).plot(ax=ax)\n",
    "    \n",
    "    ax.legend(['Fitted Student\\'s t distribution', 'Distribution of residuals'], \n",
    "              frameon=True, shadow=True, fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c487ce0",
   "metadata": {},
   "source": [
    "Outliers found in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52594ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers_global = global_outlier_detect(resid, c=5)\n",
    "outliers_local = local_outlier_detect(resid, min_samples=0.6, c=5)\n",
    "outliers = np.logical_and(outliers_global, outliers_local)\n",
    "\n",
    "print(f'Number of outliers found: {outliers.sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "76c0cf50",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data['temperature'] = temperature\n",
    "merged_data['temperature_outlier'] = outliers\n",
    "merged_data['temperature_outlier'] = merged_data['temperature_outlier'].fillna(value=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e5d85a",
   "metadata": {},
   "source": [
    "All outliers - except for consumption - are replaced by NaN. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "34184750",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = merged_data.filter(like='outlier', axis=1).columns\n",
    "to_drop = []\n",
    "\n",
    "for col in columns:\n",
    "    feature, _ = col.split('_')\n",
    "    if feature != 'consumption':\n",
    "        merged_data[feature] = merged_data[feature].mask(merged_data[col], np.nan)\n",
    "        to_drop.append(col)\n",
    "        \n",
    "merged_data = merged_data.drop(to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11a7afa",
   "metadata": {},
   "source": [
    "### Impute missing values in the temperature data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe617f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of missing temperature values before: {}'\n",
    "          .format(merged_data['temperature'].isna().sum())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "7454c697",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data['temperature'] = linear_impute(merged_data['temperature'], window=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c830b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of missing temperature values after: {}'\n",
    "          .format(merged_data['temperature'].isna().sum())\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347ca7c4",
   "metadata": {},
   "source": [
    "### Ensure that enough training data is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "d55ec498",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_condition = (  merged_data['consumption_outlier'] \n",
    "                     | merged_data['consumption'].isna() \n",
    "                     | merged_data['temperature'].isna()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "7a24561f",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing = merged_data[['consumption']].mask(missing_condition, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "8ec40880",
   "metadata": {},
   "outputs": [],
   "source": [
    "avail_data = dict()\n",
    "\n",
    "for month_year, group in missing.groupby([lambda x: x.year, lambda x: x.month]):\n",
    "    check = check_column_values_not_null(data=group, column='consumption', mostly=0.9)\n",
    "    avail_data[month_year] = check.result['unexpected_percent']\n",
    "\n",
    "avail_data = {f'{key[0]}M{key[1]}' :val for key, val in avail_data.items()}\n",
    "avail_data = pd.DataFrame.from_dict(avail_data, orient='index', columns=['values'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a07f1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Months with not enough data are:')\n",
    "print(avail_data[avail_data['values'] > 0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83200d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.style.context('seaborn-whitegrid'):    \n",
    "    fig = plt.figure(figsize=(12, 3.54), dpi=96)\n",
    "    layout = (1, 1)\n",
    "    ax = plt.subplot2grid(layout, (0, 0))\n",
    "    \n",
    "    subset = avail_data.mask(avail_data['values'] <= 0.1, 0) \n",
    "    subset.plot.bar(rot=25, ax=ax, color='#C71585', legend=False)\n",
    "    \n",
    "    subset = avail_data.mask(avail_data['values'] > 0.1, 0)\n",
    "    subset.plot.bar(rot=25, ax=ax, color='#4682B4', legend=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b512ae5e",
   "metadata": {},
   "source": [
    "### Save to the catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "17a36079",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog.save('train.preprocessed_data', merged_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4661d197",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fe8e63b2",
   "metadata": {},
   "source": [
    "--------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
